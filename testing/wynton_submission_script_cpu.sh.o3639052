GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id wu9mpwx1.
wandb: Tracking run with wandb version 0.18.3
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

  | Name            | Type            | Params | Mode 
------------------------------------------------------------
0 | eval_metrics    | ModuleDict      | 0      | train
1 | initial_conv    | CNNModule       | 5.4 K  | train
2 | dilated_convs   | ModuleList      | 111 K  | train
3 | crop_layers     | ModuleList      | 0      | train
4 | global_avg_pool | GlobalAvgPool1D | 0      | train
5 | count_dense     | Linear          | 65.0 K | train
------------------------------------------------------------
181 K     Trainable params
0         Non-trainable params
181 K     Total params
0.726     Total estimated model params size (MB)
50        Modules in train mode
0         Modules in eval mode
Using device: cpu
Read in bed file of 20512 peaks
Read in bed file of 16900 peaks
Successfully loaded in data with 14781 positive and 0 nonpeak regions!
Given config['out_pred_len'] = 1000, we need input_len = 3064 

Current sequence length is 3107
BPNetLightning(
  (eval_metrics): ModuleDict(
    (mse): MSELoss()
    (kl_divergence): KLDivergence()
    (explained_variance): ExplainedVariance()
    (cosine_similarity): CosineSimilarity()
    (mae): MeanAbsoluteError()
    (r2): R2Score()
  )
  (initial_conv): CNNModule(
    (conv): Conv1d(4, 64, kernel_size=(21,), stride=(1,))
    (activation): ReLU()
  )
  (dilated_convs): ModuleList(
    (0): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(2,))
      (activation): ReLU()
    )
    (1): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(4,))
      (activation): ReLU()
    )
    (2): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(8,))
      (activation): ReLU()
    )
    (3): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(16,))
      (activation): ReLU()
    )
    (4): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(32,))
      (activation): ReLU()
    )
    (5): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(64,))
      (activation): ReLU()
    )
    (6): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(128,))
      (activation): ReLU()
    )
    (7): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(256,))
      (activation): ReLU()
    )
    (8): DilatedConvModule(
      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(512,))
      (activation): ReLU()
    )
  )
  (crop_layers): ModuleList(
    (0-8): 9 x Cropping1D()
  )
  (global_avg_pool): GlobalAvgPool1D()
  (count_dense): Linear(in_features=64, out_features=1000, bias=True)
)
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s][1;34mwandb[0m:
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync ./wandb/offline-run-20241010_143009-wu9mpwx1[0m
Traceback (most recent call last):
  File "training_script.py", line 99, in <module>
    main()
  File "training_script.py", line 96, in main
    trainer.fit(logger_out=wandb_logger)
  File "/wynton/home/corces/vishvak/pytorch_cbp/models/_model.py", line 73, in fit
    self.trainer.fit(self.model, self.train_dataloader, self.valid_dataloader)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/wynton/home/corces/vishvak/pytorch_cbp/models/_module.py", line 166, in validation_step
    loss = self.log_metrics(y_hat_count,y,"val")
  File "/wynton/home/corces/vishvak/pytorch_cbp/models/_module.py", line 147, in log_metrics
    metrics = self.calculate_metrics(y_hat, y)
  File "/wynton/home/corces/vishvak/pytorch_cbp/models/_module.py", line 142, in calculate_metrics
    results[metric_name] = metric_fn(y_hat, y)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torchmetrics/metric.py", line 312, in forward
    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torchmetrics/metric.py", line 381, in _forward_reduce_state_update
    self.update(*args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torchmetrics/metric.py", line 493, in wrapped_func
    raise err
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torchmetrics/metric.py", line 483, in wrapped_func
    update(*args, **kwargs)
  File "/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torchmetrics/regression/r2.py", line 132, in update
    self.sum_squared_error += sum_squared_error
RuntimeError: output with shape [1] doesn't match the broadcast shape [1000]
==============================================================
job_number:                 3639052
exec_file:                  job_scripts/3639052
submission_time:            Thu Oct 10 14:29:18 2024
owner:                      vishvak
uid:                        64006
group:                      corces
gid:                        60243
sge_o_home:                 /wynton/home/corces/vishvak
sge_o_log_name:             vishvak
sge_o_path:                 /wynton/home/corces/vishvak/miniforge3/bin:/wynton/home/corces/vishvak/miniforge3/condabin:/wynton/home/corces/vishvak/.local/bin:/wynton/home/corces/vishvak/bin:/opt/sge/bin:/opt/sge/bin/lx-amd64:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
sge_o_shell:                /bin/bash
sge_o_workdir:              /wynton/home/corces/vishvak/pytorch_cbp/testing
sge_o_host:                 gpudev1
account:                    sge
cwd:                        /wynton/home/corces/vishvak/pytorch_cbp/testing
merge:                      y
hard resource_list:         h_rt=172800,mem_free=1G
mail_list:                  vishvak@gpudev1.wynton.ucsf.edu
notify:                     FALSE
job_name:                   wynton_submission_script_cpu.sh
jobshare:                   0
hard_queue_list:            !*gpu.q
shell_list:                 NONE:/bin/bash
env_list:                   TERM=NONE
script_file:                wynton_submission_script_cpu.sh
parallel environment:  smp range: 4
project:                    corceslab
binding:                    NONE
job_type:                   NONE
usage         1:            cpu=00:00:22, mem=9.78837 GB s, io=1.68388 GB, vmem=757.480M, maxvmem=1.091G
binding       1:            NONE
scheduling info:            (Collecting of scheduler job information is turned off)
