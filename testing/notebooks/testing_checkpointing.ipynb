{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models._model import CBPLTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"peak_regions\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/pd_data/Microglia_peak_set_2.bed\",\n",
    "    \"nonpeak_regions\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/own_data/test.chr1.negatives.adjusted.bed\",\n",
    "    \"genome_fasta\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/data/downloads/hg38.fa\",\n",
    "    \"cts_bw_file\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/pd_data/nd_Microglia_merge.bw\",\n",
    "    \"negative_sampling_ratio\":0,\n",
    "    #\"train_size\": 0.9,\n",
    "    \"batch_size\": 64,\n",
    "    \"filters\": 256,\n",
    "    \"n_dil_layers\": 11,\n",
    "    \"conv1_kernel_size\": 15,\n",
    "    \"dilation_kernel_size\" : 2,\n",
    "    \"num_tasks\": 1,\n",
    "    \"input_seq_len\":6500,\n",
    "    \"out_pred_len\": 750,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"dropout_rate\" : 0.1,\n",
    "    \"train_chrs\" : [\"chr1\",\"chr2\",\"chr3\",\"chr4\",\"chr5\",\"chr6\",\"chr7\",\"chr8\",\"chr9\",\"chr10\"],\n",
    "    \"valid_chrs\" : [\"chr10\",\"chr11\",\"chr12\",\"chr13\",\"chr14\"],\n",
    "    \"seq_focus_len\" : 500,\n",
    "    \"loss\" : \"weighted_norm_mse\",\n",
    "    \"use_attention_pooling\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in bed file of 151351 regions\n",
      "Read in bed file of 16900 regions\n",
      "Loaded 151351 peak regions and 0 non-peak regions\n",
      "Loading model from checkpoint: /wynton/home/corces/vishvak/pytorch_cbp/testing/cbpl_microglia/p7t2wwpb/checkpoints/epoch=13-step=36512.ckpt\n"
     ]
    }
   ],
   "source": [
    "trainer =  CBPLTrainer(config,checkpoint_path='/wynton/home/corces/vishvak/pytorch_cbp/testing/cbpl_microglia/p7t2wwpb/checkpoints/epoch=13-step=36512.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-11-08 17:09:09.590506: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-11-08 17:09:09.590619: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorboard/compat/__init__.py:42\u001b[0m, in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m notf  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/wynton/home/corces/vishvak/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    576\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:943\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mprepare_data()\n\u001b[0;32m--> 943\u001b[0m call\u001b[39m.\u001b[39;49m_call_setup_hook(\u001b[39mself\u001b[39;49m)  \u001b[39m# allow user to set up LightningModule in accelerator environment\u001b[39;00m\n\u001b[1;32m    944\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: configuring model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:96\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m logger \u001b[39min\u001b[39;00m trainer\u001b[39m.\u001b[39mloggers:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(logger, \u001b[39m\"\u001b[39;49m\u001b[39mexperiment\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m     97\u001b[0m         _ \u001b[39m=\u001b[39m logger\u001b[39m.\u001b[39mexperiment\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/lightning_fabric/loggers/logger.py:118\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m _DummyExperiment()\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/lightning_fabric/loggers/tensorboard.py:190\u001b[0m, in \u001b[0;36mTensorBoardLogger.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m _TENSORBOARD_AVAILABLE:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdel\u001b[39;00m tensorboard\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwriter\u001b[39;00m \u001b[39mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummary\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwriter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrecord_writer\u001b[39;00m \u001b[39mimport\u001b[39;00m RecordWriter  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py:19\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_convert_np\u001b[39;00m \u001b[39mimport\u001b[39;00m make_np\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_embedding\u001b[39;00m \u001b[39mimport\u001b[39;00m get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_onnx_graph\u001b[39;00m \u001b[39mimport\u001b[39;00m load_onnx_graph\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/torch/utils/tensorboard/_embedding.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprojector\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprojector_config_pb2\u001b[39;00m \u001b[39mimport\u001b[39;00m EmbeddingInfo\n\u001b[0;32m---> 10\u001b[0m _HAS_GFILE_JOIN \u001b[39m=\u001b[39m \u001b[39mhasattr\u001b[39m(tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39mgfile, \u001b[39m\"\u001b[39m\u001b[39mjoin\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gfile_join\u001b[39m(a, b):\n\u001b[1;32m     14\u001b[0m     \u001b[39m# The join API is different between tensorboard's TF stub and TF:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39m# https://github.com/tensorflow/tensorboard/issues/6080\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39m# We need to try both because `tf` may point to either the stub or the real TF.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorboard/lazy.py:65\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.LazyModule.__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr_name):\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(load_once(\u001b[39mself\u001b[39;49m), attr_name)\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorboard/lazy.py:97\u001b[0m, in \u001b[0;36m_memoize.<locals>.wrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[39mif\u001b[39;00m cache\u001b[39m.\u001b[39mget(arg, nothing) \u001b[39mis\u001b[39;00m nothing:\n\u001b[0;32m---> 97\u001b[0m             cache[arg] \u001b[39m=\u001b[39m f(arg)\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m cache[arg]\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorboard/lazy.py:50\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.load_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     module \u001b[39m=\u001b[39m load_fn()\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorboard/compat/__init__.py:45\u001b[0m, in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m tensorflow\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/__init__.py:42\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/data/__init__.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m AUTOTUNE\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/data/experimental/__init__.py:95\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m service\n\u001b[1;32m     96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_ragged_batch\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/data/experimental/service/__init__.py:387\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mThis module contains:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m    388\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_dataset_id\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:23\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m compression_ops\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_server_lib\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py:16\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[39mas\u001b[39;00m ged_ops\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:30\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragged\u001b[39;00m \u001b[39mimport\u001b[39;00m ragged_tensor\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_logging \u001b[39mas\u001b[39;00m logging\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_tensor.py:24\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m session\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m composite_tensor\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/tensorflow/python/client/session.py:37\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m session_ops\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_logging \u001b[39mas\u001b[39;00m logging\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:839\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:934\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1033\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/wynton/home/corces/vishvak/pytorch_cbp/testing/testing_checkpointing.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpudev1.wynton.ucsf.edu/wynton/home/corces/vishvak/pytorch_cbp/testing/testing_checkpointing.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[0;32m~/pytorch_cbp/models/_model.py:103\u001b[0m, in \u001b[0;36mCBPLTrainer.fit\u001b[0;34m(self, max_epochs, batch_size, early_stopping_patience, check_val_every_n_epoch, save_path, logger_out, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m     76\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m     77\u001b[0m     EarlyStopping(\n\u001b[1;32m     78\u001b[0m         monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m ]\n\u001b[1;32m     92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m     93\u001b[0m     max_epochs\u001b[39m=\u001b[39mmax_epochs,\n\u001b[1;32m     94\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m    101\u001b[0m )\n\u001b[0;32m--> 103\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader, \n\u001b[1;32m    106\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalid_dataloader\n\u001b[1;32m    107\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    540\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/chrombpnet/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[39m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     exit(\u001b[39m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "\"\"\"\n",
    "# Initialize from scratch\n",
    "trainer = CBPLTrainer(config)\n",
    "\n",
    "# Or initialize from checkpoint\n",
    "trainer = CBPLTrainer(config, checkpoint_path='path/to/checkpoint.ckpt')\n",
    "\n",
    "# Train from scratch\n",
    "trainer.fit(\n",
    "    max_epochs=50,\n",
    "    save_path='checkpoints',\n",
    "    logger_out=wandb_logger\n",
    ")\n",
    "\n",
    "# Or continue training from a checkpoint\n",
    "trainer.fit(\n",
    "    max_epochs=50,\n",
    "    save_path='checkpoints',\n",
    "    logger_out=wandb_logger,\n",
    "    resume_from_checkpoint='path/to/checkpoint.ckpt'\n",
    ")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chrombpnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
