{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models._model import CBPLTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"peak_regions\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/own_data/test.chr1.chr2.chr3.bed\",\n",
    "    \"nonpeak_regions\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/own_data/test.chr1.negatives.adjusted.bed\",\n",
    "    \"genome_fasta\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/data/downloads/hg38.fa\",\n",
    "    \"cts_bw_file\":\"/gladstone/corces/lab/users/vishvak/chrombpnet_tutorial/own_data/ENCFF735AHG.bigWig\",\n",
    "    \"negative_sampling_ratio\":0.1,\n",
    "    \"train_size\": 0.7,\n",
    "    \"batch_size\": 32,\n",
    "    \"filters\": 64,\n",
    "    \"n_dil_layers\": 9,\n",
    "    \"conv1_kernel_size\": 21,\n",
    "    \"dilation_kernel_size\" : 3,\n",
    "    \"num_tasks\": 1,\n",
    "    \"input_seq_len\": 3107,\n",
    "    \"out_pred_len\": 1000,\n",
    "    \"learning_rate\": 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in bed file of 20512 peaks\n",
      "Read in bed file of 16900 peaks\n",
      "Successfully loaded in data with 14781 positive and 1478 nonpeak regions!\n",
      "Given config['out_pred_len'] = 1000, we need input_len = 3064 \n",
      "\n",
      "Current sequence length is 3107\n"
     ]
    }
   ],
   "source": [
    "trainer =  CBPLTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNetLightning(\n",
       "  (mse_loss): MSELoss()\n",
       "  (initial_conv): CNNModule(\n",
       "    (conv): Conv1d(4, 64, kernel_size=(21,), stride=(1,))\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (dilated_convs): ModuleList(\n",
       "    (0): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (1): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(4,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (2): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(8,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (3): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(16,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (4): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(32,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (5): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(64,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (6): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(128,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (7): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(256,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (8): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(512,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (crop_layers): ModuleList(\n",
       "    (0-8): 9 x Cropping1D()\n",
       "  )\n",
       "  (global_avg_pool): GlobalAvgPool1D()\n",
       "  (count_dense): Linear(in_features=64, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10823, 4, 3106])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.dataset.seqs.shape #old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22913, 4, 3106])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.dataset.seqs.shape #new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22913, 1000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.dataset.cts.shape #new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['chr1', '100038498', 'f', '1'],\n",
       "       ['chr1', '100047038', 'f', '1'],\n",
       "       ['chr1', '100132973', 'f', '1'],\n",
       "       ...,\n",
       "       ['chr1', '232944057', 'f', '0'],\n",
       "       ['chr1', '87139057', 'f', '0'],\n",
       "       ['chr1', '57972057', 'f', '0']], dtype='<U21')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.dataset.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 3106])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNetLightning(\n",
       "  (mse_loss): MSELoss()\n",
       "  (initial_conv): CNNModule(\n",
       "    (conv): Conv1d(4, 64, kernel_size=(64,), stride=(1,))\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (dilated_convs): ModuleList(\n",
       "    (0): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(2,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (1): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(4,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (2): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(8,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (3): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(16,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (4): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(32,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (5): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(64,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (6): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(128,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (7): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(256,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (8): DilatedConvModule(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), dilation=(512,))\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (crop_layers): ModuleList(\n",
       "    (0-8): 9 x Cropping1D()\n",
       "  )\n",
       "  (global_avg_pool): GlobalAvgPool1D()\n",
       "  (count_dense): Linear(in_features=64, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting size:torch.Size([32, 4, 3106])\n",
      "after first convolution:torch.Size([32, 64, 3086])\n",
      "after 1th dilation:torch.Size([32, 64, 3082])\n",
      "after 1th crop:torch.Size([32, 64, 3082])\n",
      "after 2th dilation:torch.Size([32, 64, 3074])\n",
      "after 2th crop:torch.Size([32, 64, 3074])\n",
      "after 3th dilation:torch.Size([32, 64, 3058])\n",
      "after 3th crop:torch.Size([32, 64, 3058])\n",
      "after 4th dilation:torch.Size([32, 64, 3026])\n",
      "after 4th crop:torch.Size([32, 64, 3026])\n",
      "after 5th dilation:torch.Size([32, 64, 2962])\n",
      "after 5th crop:torch.Size([32, 64, 2962])\n",
      "after 6th dilation:torch.Size([32, 64, 2834])\n",
      "after 6th crop:torch.Size([32, 64, 2834])\n",
      "after 7th dilation:torch.Size([32, 64, 2578])\n",
      "after 7th crop:torch.Size([32, 64, 2578])\n",
      "after 8th dilation:torch.Size([32, 64, 2066])\n",
      "after 8th crop:torch.Size([32, 64, 2066])\n",
      "after 9th dilation:torch.Size([32, 64, 1042])\n",
      "after 9th crop:torch.Size([32, 64, 1042])\n",
      "after pool:torch.Size([32, 64])\n",
      "count dimensions : torch.Size([32, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.8343, 0.0831, 0.4164],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.8467, 0.0997, 0.4460],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.8241, 0.0718, 0.4070],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.8386, 0.0786, 0.4137],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.8198, 0.0697, 0.4092],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.8246, 0.0642, 0.4073]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in trainer.train_dataloader:\n",
    "    inputs, targets = batch\n",
    "    break  \n",
    "trainer.model.forward_test(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chrombpnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
